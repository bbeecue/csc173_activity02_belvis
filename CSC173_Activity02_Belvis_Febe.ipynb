{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8booLjMPIvv"
      },
      "source": [
        "# Neural Network from Scratch Using PyTorch and Custom Dataset\n",
        "\n",
        "In this activity, you will be introduced to PyTorch basics by implementing a simple neural network using a custom dataset (student pass/fail presented in previous session)\n",
        "\n",
        "First we install PyTorch along with some other dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLWAx9uIOvuA",
        "outputId": "7d3f30ac-ae32-48ad-d674-f50b80821aa7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "sns.set_palette('husl')\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "\n",
        "### Optional: If CUDA available: False\n",
        "### 1. Go to the Runtime menu.\n",
        "### 2. Select Change runtime type.\n",
        "### 3. Set Hardware accelerator to available GPU and save."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGmQ2PdQgzDl"
      },
      "source": [
        "and also our function to generate our custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Lmqi9KtkgydS"
      },
      "outputs": [],
      "source": [
        "def generate_pass_fail_dataset(n_samples=100, random_state=42):\n",
        "    # Ensure n_samples is even for equal split\n",
        "    n_samples = n_samples if n_samples % 2 == 0 else n_samples + 1\n",
        "    n_per_class = n_samples // 2\n",
        "\n",
        "    # Generate FAIL samples (low study hours, low attendance)\n",
        "    # Students who DON'T meet: study_hours > 5 AND attendance > 70%\n",
        "    fail_study_hours = np.random.normal(loc=3, scale=1.5, size=n_per_class) #most study around 3 hours, values range from 0-6 hours\n",
        "    fail_study_hours = np.clip(fail_study_hours, 0, 6)  # Keep mostly below 5\n",
        "\n",
        "    fail_attendance = np.random.normal(loc=50, scale=15, size=n_per_class)\n",
        "    fail_attendance = np.clip(fail_attendance, 0, 75)  # Keep mostly below 70%\n",
        "    fail_labels = np.zeros(n_per_class, dtype=int)\n",
        "\n",
        "    # Generate PASS samples (high study hours, high attendance)\n",
        "    # Students who meet: study_hours > 5 AND attendance > 70%\n",
        "    pass_study_hours = np.random.normal(loc=7.5, scale=1.2, size=n_per_class)\n",
        "    pass_study_hours = np.clip(pass_study_hours, 5, 10)  # Keep mostly above 5\n",
        "\n",
        "    pass_attendance = np.random.normal(loc=85, scale=10, size=n_per_class)\n",
        "    pass_attendance = np.clip(pass_attendance, 70, 100)  # Keep mostly above 70%\n",
        "\n",
        "    pass_labels = np.ones(n_per_class, dtype=int)\n",
        "\n",
        "    # Combine both classes\n",
        "    study_hours = np.concatenate([fail_study_hours, pass_study_hours])\n",
        "    attendance_rate = np.concatenate([fail_attendance, pass_attendance])\n",
        "    y = np.concatenate([fail_labels, pass_labels])\n",
        "\n",
        "    # Shuffle the data\n",
        "    shuffle_idx = np.random.permutation(n_samples)\n",
        "    study_hours = study_hours[shuffle_idx]\n",
        "    attendance_rate = attendance_rate[shuffle_idx]\n",
        "    y = y[shuffle_idx]\n",
        "\n",
        "    # Combine features into a matrix\n",
        "    X = np.column_stack((study_hours, attendance_rate))\n",
        "    df = pd.DataFrame({'study_hours': study_hours, 'attendance_rate': attendance_rate, 'label': y})\n",
        "\n",
        "    return X, y, df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7oNITLEZSWl"
      },
      "source": [
        "## What is PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM2bDrxqZYTq"
      },
      "source": [
        "PyTorch is a machine learning library, like TensorFlow. At its core, PyTorch provides an interface for creating and manipulating [tensors](https://pytorch.org/docs/stable/tensors.html), which are data structures that you can think of as multi-dimensional arrays.\n",
        "\n",
        "Tensors are represented as n-dimensional arrays of base datatypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions. PyTorch provides the ability to perform computation on these tensors, define neural networks, and train them efficiently.\n",
        "\n",
        "The [```shape```](https://pytorch.org/docs/stable/generated/torch.Tensor.shape.html#torch.Tensor.shape) of a PyTorch tensor defines its number of dimensions and the size of each dimension. The `ndim` or [```dim```](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html#torch.Tensor.dim) of a PyTorch tensor provides the number of dimensions (n-dimensions) -- this is equivalent to the tensor's rank (as is used in TensorFlow), and you can also think of this as the tensor's order or degree.\n",
        "\n",
        "Let’s start by creating some tensors and inspecting their properties:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APeCmvNlZ1dY",
        "outputId": "8280c4bd-d7dd-44bd-e48d-050a8ebd157e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`integer` is a 0-d Tensor: 1234\n",
            "`decimal` is a 0-d Tensor: 3.1415927410125732\n"
          ]
        }
      ],
      "source": [
        "integer = torch.tensor(1234)\n",
        "decimal = torch.tensor(3.14159265359)\n",
        "\n",
        "print(f\"`integer` is a {integer.ndim}-d Tensor: {integer}\")\n",
        "print(f\"`decimal` is a {decimal.ndim}-d Tensor: {decimal}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFTXOb28aAd4"
      },
      "source": [
        "Vectors and lists can be used to create 1-d tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "sOqIizvLaA7F"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`fibonacci` is a 1-d Tensor with shape: torch.Size([6])\n",
            "`count_to_100` is a 1-d Tensor with shape: torch.Size([100])\n"
          ]
        }
      ],
      "source": [
        "fibonacci = torch.tensor([1, 1, 2, 3, 5, 8])\n",
        "count_to_100 = torch.tensor(range(100))\n",
        "\n",
        "print(f\"`fibonacci` is a {fibonacci.ndim}-d Tensor with shape: {fibonacci.shape}\")\n",
        "print(f\"`count_to_100` is a {count_to_100.ndim}-d Tensor with shape: {count_to_100.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-bzKfpiaFNE"
      },
      "source": [
        "Next, let’s create 2-d (i.e., matrices) and higher-rank tensors.\n",
        "\n",
        "In image processing and computer vision, we will use 4-d Tensors with dimensions corresponding to batch size, number of color channels, image height, and image width."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmZ3Scl1aJjj",
        "outputId": "ea5f89af-7382-494b-e0fa-af38e99a4288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "images is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "### Defining higher-order Tensors ###\n",
        "\n",
        "'''A 2-d Tensor'''\n",
        "matrix = torch.tensor([[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]])\n",
        "\n",
        "'''A 4-d Tensor.'''\n",
        "#   You can think of this as 10 images where each image is RGB 256 x 256.\n",
        "images = torch.zeros(10, 3, 256, 256)\n",
        "\n",
        "assert images.shape == (10, 3, 256, 256), \"images is incorrect shape\"\n",
        "print(f\"images is a {images.ndim}-d Tensor with shape: {images.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8giGiaYcLjf"
      },
      "source": [
        "As you have seen, the `shape` of a tensor provides the number of elements in each tensor dimension. The `shape` is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank tensor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "F6tzwNs3cNEA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "`row_vector`: tensor([5., 6., 7., 8.])\n",
            "`column_vector`: tensor([2., 6.])\n",
            "`scalar`: 2.0\n"
          ]
        }
      ],
      "source": [
        "row_vector = matrix[1]\n",
        "column_vector = matrix[:, 1]\n",
        "scalar = matrix[0, 1]\n",
        "\n",
        "print(f\"`row_vector`: {row_vector}\")\n",
        "print(f\"`column_vector`: {column_vector}\")\n",
        "print(f\"`scalar`: {scalar}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BeXp6zocVdQ"
      },
      "source": [
        "## Computations on Tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFklK19nce__"
      },
      "source": [
        "A convenient way to think about and visualize computations in a machine learning framework like PyTorch is in terms of graphs. We can define this graph in terms of tensors, which hold data, and the mathematical operations that act on these tensors in some order. Let's look at a simple example, and define this computation using PyTorch:\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/add-graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUxtF17ecje_"
      },
      "source": [
        "Notice how we've created a computation graph consisting of PyTorch operations, and how the output is a tensor with value 76.\n",
        "\n",
        "Now let's consider a slightly more complicated example:\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/computation-graph.png)\n",
        "\n",
        "Here, we take two inputs, `a, b`, and compute an output `e`. Each node in the graph represents an operation that takes some input, does some computation, and passes its output to another node.\n",
        "\n",
        "Let's define a simple function in PyTorch to construct this computation function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PqWoxsz0cxxS"
      },
      "outputs": [],
      "source": [
        "### Defining Tensor computations ###\n",
        "\n",
        "# A simple computation function\n",
        "def func(a, b):\n",
        "    c = torch.add(a, b)\n",
        "    d = torch.subtract(b, 1)\n",
        "    e = torch.multiply(c, d)\n",
        "    return e\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDGgIEdGc51O"
      },
      "source": [
        "Now, we can call this function to execute the computation graph given some inputs `a,b`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eti9AG6-c6XB",
        "outputId": "786c8a09-2ac6-4b58-cf24-3c29297d3bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "e_out: 6.0\n"
          ]
        }
      ],
      "source": [
        "# Consider example values for a,b\n",
        "a, b = 1.5, 2.5\n",
        "# Execute the computation\n",
        "e_out = func(a, b)\n",
        "print(f\"e_out: {e_out}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acy6xmSYc_cT"
      },
      "source": [
        "Notice how our output is a tensor with value defined by the output of the computation, and that the output has no shape as it is a single scalar value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4E0MNtvdLB9"
      },
      "source": [
        "## Neural networks in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEYYEhsmdVQK"
      },
      "source": [
        "We can also define neural networks in PyTorch. PyTorch uses [``torch.nn.Module``](https://pytorch.org/docs/stable/generated/torch.nn.Module.html), which serves as a base class for all neural network modules in PyTorch and thus provides a framework for building and training neural networks.\n",
        "\n",
        "Let's consider the example of a simple perceptron defined by just one dense (aka fully-connected or linear) layer: $ y = \\sigma(Wx + b) $, where $W$ represents a matrix of weights, $b$ is a bias, $x$ is the input, $\\sigma$ is the sigmoid activation function, and $y$ is the output.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/MITDeepLearning/introtodeeplearning/2025/lab1/img/computation-graph-2.png)\n",
        "\n",
        "We will use `torch.nn.Module` to define layers -- the building blocks of neural networks. Layers implement common neural networks operations. In PyTorch, when we implement a layer, we subclass `nn.Module` and define the parameters of the layer as attributes of our new class. We also define and override a function [``forward``](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.forward), which will define the forward pass computation that is performed at every step. All classes subclassing `nn.Module` should override the `forward` function.\n",
        "\n",
        "Let's write a dense layer class to implement a perceptron defined above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PJufkBJ4diyC"
      },
      "outputs": [],
      "source": [
        "### Defining a dense layer ###\n",
        "\n",
        "# num_inputs: number of input nodes\n",
        "# num_outputs: number of output nodes\n",
        "# x: input to the layer\n",
        "\n",
        "class OurDenseLayer(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super(OurDenseLayer, self).__init__()\n",
        "        # Define and initialize parameters: a weight matrix W and bias b\n",
        "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
        "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = torch.matmul(x, self.W) + self.bias\n",
        "        y = torch.sigmoid(z)\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isDWtUbwdz4S"
      },
      "source": [
        "Now, let's test the output of our layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHbZL-2TdzRX",
        "outputId": "9ce7ee78-34e1-450f-d7b1-ab88fe910f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.5147, 0.1955, 0.0040]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Define a layer and test the output!\n",
        "num_inputs = 2\n",
        "num_outputs = 3\n",
        "layer = OurDenseLayer(num_inputs, num_outputs)\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "y = layer(x_input)\n",
        "\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {y.shape}\")\n",
        "print(f\"output result: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH6aTNIed_1j"
      },
      "source": [
        "Conveniently, PyTorch has defined a number of ```nn.Modules``` (or Layers) that are commonly used in neural networks, for example a [```nn.Linear```](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) or [`nn.Sigmoid`](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html) module.\n",
        "\n",
        "Now, instead of using a single ```Module``` to define our simple neural network, we'll use the  [`nn.Sequential`](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) module from PyTorch and a single [`nn.Linear` ](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) layer to define our network. With the `Sequential` API, you can readily create neural networks by stacking together layers like building blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Oa3NeC_SeAnk"
      },
      "outputs": [],
      "source": [
        "### Defining a neural network using the PyTorch Sequential API ###\n",
        "\n",
        "# define the number of inputs and outputs\n",
        "n_input_nodes = 2\n",
        "n_output_nodes = 3\n",
        "\n",
        "# Define the model\n",
        "model = nn.Sequential(\n",
        "    # linear layer with input size 2 and output size 3\n",
        "    nn.Linear(n_input_nodes, n_output_nodes),\n",
        "    # Sigmoid activation function\n",
        "    nn.Sigmoid()\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRbL8kzseOqf"
      },
      "source": [
        "We've defined our model using the Sequential API. Now, we can test it out using an example input:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7duKPzleOI2",
        "outputId": "ead97686-b9e7-4de4-b106-24790fa0915f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.5147, 0.1955, 0.0040]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Test the model with example input\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "model_output = model(x_input)\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {y.shape}\")\n",
        "print(f\"output result: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_yhFRPdeUHT"
      },
      "source": [
        "With PyTorch, we can create more flexible models by subclassing [`nn.Module`](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). The `nn.Module` class allows us to group layers together flexibly to define new architectures.\n",
        "\n",
        "As we saw earlier with `OurDenseLayer`, we can subclass `nn.Module` to create a class for our model, and then define the forward pass through the network using the `forward` function. Subclassing affords the flexibility to define custom layers, custom training loops, custom activation functions, and custom models. Let's define the same neural network model as above (i.e., Linear layer with an activation function after it), now using subclassing and using PyTorch's built in linear layer from `nn.Linear`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2XGG3jX5edXQ"
      },
      "outputs": [],
      "source": [
        "### Defining a model using subclassing ###\n",
        "\n",
        "class LinearWithSigmoidActivation(nn.Module):\n",
        "    def __init__(self, num_inputs, num_outputs):\n",
        "        super(LinearWithSigmoidActivation, self).__init__()\n",
        "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
        "        self.activation = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        linear_output = self.linear(inputs)\n",
        "        output = self.activation(linear_output)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mh48zbUseohC"
      },
      "source": [
        "Let's test out our new model, using an example input, setting `n_input_nodes=2` and `n_output_nodes=3` as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXDNvSaSeoRE",
        "outputId": "202614fa-6c34-48eb-bdb0-dc5f7f1cf37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input shape: torch.Size([1, 2])\n",
            "output shape: torch.Size([1, 3])\n",
            "output result: tensor([[0.6035, 0.3889, 0.7915]], grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ],
      "source": [
        "n_input_nodes = 2\n",
        "n_output_nodes = 3\n",
        "model = LinearWithSigmoidActivation(n_input_nodes, n_output_nodes)\n",
        "x_input = torch.tensor([[1, 2.]])\n",
        "y = model(x_input)\n",
        "print(f\"input shape: {x_input.shape}\")\n",
        "print(f\"output shape: {y.shape}\")\n",
        "print(f\"output result: {y}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D60RPNM_e0uD"
      },
      "source": [
        "## Automatic Differentiation in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3bxB4Dze5Rq"
      },
      "source": [
        "In PyTorch, [`torch.autograd`](https://pytorch.org/docs/stable/autograd.html) is used for [automatic differentiation](https://en.wikipedia.org/wiki/Automatic_differentiation), which is critical for training deep learning models with [backpropagation](https://en.wikipedia.org/wiki/Backpropagation).\n",
        "\n",
        "We will use the PyTorch [`.backward()`](https://pytorch.org/docs/stable/generated/torch.Tensor.backward.html) method to trace operations for computing gradients. On a tensor, the [`requires_grad`](https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad_.html) attribute controls whether autograd should record operations on that tensor. When a forward pass is made through the network, PyTorch builds a computational graph dynamically; then, to compute the gradient, the `backward()` method is called to perform backpropagation.\n",
        "\n",
        "Let's compute the gradient of $ y = x^2 $:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzP4RTCBe_Ec",
        "outputId": "51a7749e-80cc-4a35-97a5-82645f61c3d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dy_dx of y=x^2 at x=3.0 is:  tensor(6.)\n"
          ]
        }
      ],
      "source": [
        "### Gradient computation ###\n",
        "\n",
        "# y = x^2\n",
        "# Example: x = 3.0\n",
        "x = torch.tensor(3.0, requires_grad=True)\n",
        "y = x ** 2\n",
        "y.backward()  # Compute the gradient\n",
        "\n",
        "dy_dx = x.grad\n",
        "print(\"dy_dx of y=x^2 at x=3.0 is: \", dy_dx)\n",
        "assert dy_dx == 6.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNsXTydufFZ6"
      },
      "source": [
        "In training neural networks, we use differentiation and stochastic gradient descent (SGD) to optimize a loss function. Now that we have a sense of how PyTorch's autograd can be used to compute and access derivatives, we will look at an example where we use automatic differentiation and SGD to find the minimum of $ L=(x-x_f)^2 $. Here $x_f$ is a variable for a desired value we are trying to optimize for; $L$ represents a loss that we are trying to minimize."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "J6ex1KPAfO_-",
        "outputId": "4ff91ec4-fa2c-4c11-f848-37abde804c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing x=0.6650150418281555\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Function minimization with autograd and gradient descent ###\n",
        "\n",
        "# Initialize a random value for our intial x\n",
        "x = torch.randn(1)\n",
        "print(f\"Initializing x={x.item()}\")\n",
        "\n",
        "learning_rate = 1e-2  # Learning rate\n",
        "history = []\n",
        "x_f = 4  # Target value\n",
        "\n",
        "\n",
        "# We will run gradient descent for a number of iterations. At each iteration, we compute the loss,\n",
        "#   compute the derivative of the loss with respect to x, and perform the update.\n",
        "for i in range(500):\n",
        "    x = torch.tensor([x], requires_grad=True)\n",
        "\n",
        "    # Compute the loss as the square of the difference between x and x_f\n",
        "    loss = (x - x_f) ** 2\n",
        "\n",
        "    # Backpropagate through the loss to compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update x with gradient descent\n",
        "    x = x.item() - learning_rate * x.grad\n",
        "\n",
        "    history.append(x.item())\n",
        "\n",
        "# Plot the evolution of x as we optimize toward x_f!\n",
        "plt.plot(history)\n",
        "plt.plot([0, 500], [x_f, x_f])\n",
        "plt.legend(('Predicted', 'True'))\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('x value')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9sE_GiNjN48"
      },
      "source": [
        "# **Activity: Build a student pass/fail classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBFjCebtjfZ1"
      },
      "source": [
        "Build and train a neural network to predict whether a student will pass or fail based on their study hours and attendance rate.\n",
        "\n",
        "TASKS:\n",
        "1. Load, explore, and visualize the dataset\n",
        "2. Prepare the data (convert to tensors, split train/test)\n",
        "3. Design a neural network architecture\n",
        "4. Define loss function and optimizer\n",
        "5. Train the model\n",
        "6. Evaluate performance\n",
        "7. Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c4XPR57Bh9Ld"
      },
      "outputs": [],
      "source": [
        "# TASK 1: Load, explore, and visualize the dataset  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2uJwvzDojsPu"
      },
      "outputs": [],
      "source": [
        "# TASK 2: Prepare the data\n",
        "# -- Convert to PyTorch tensors\n",
        "# -- Split into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "G1hh0avCkM_1"
      },
      "outputs": [],
      "source": [
        "# TASK 3: Implement neural network architecture\n",
        "#  -- Architecture:\n",
        "#  -- Input layer: 2 features (study_hours, attendance_rate)\n",
        "#  -- Hidden layer: 8 neurons with ReLU activation\n",
        "#  -- Hidden layer: 4 neurons with ReLU activation\n",
        "#  -- Output layer: 1 neuron with Sigmoid activation (binary classification)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_CcAlc3hkvp2"
      },
      "outputs": [],
      "source": [
        "# TASK 4: Implement loss function and optimizer\n",
        "# -- Loss function: Binary Cross-Entropy\n",
        "# -- Optimizer: Adam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7PfeJ04UlA3C"
      },
      "outputs": [],
      "source": [
        "# TASK 5: Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TpazKrtHlFxY"
      },
      "outputs": [],
      "source": [
        "# TASK 6: Evaluate performance\n",
        "# -- Predictions on test set\n",
        "# -- Calculate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_2vxdGa_lTLU"
      },
      "outputs": [],
      "source": [
        "# TASK 7: Visualize results\n",
        "# -- Plot training history\n",
        "# -- Loss curves\n",
        "# -- Decision boundary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wgt-MOBlnrZ"
      },
      "source": [
        "**REFLECTION QUESTIONS:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLyzYml0lvuw"
      },
      "source": [
        "1. Why do we use sigmoid activation in the output layer for binary classification?\n",
        "\n",
        "    > (write your answer here)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-MtZCxhl4eS"
      },
      "source": [
        "2. What would happen if we increased/decreased the number of hidden neurons?\n",
        "\n",
        "    > (write your answer here)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8C6Rsw1Cl7kT"
      },
      "source": [
        "3. How does the learning rate affect the training process?\n",
        "> (write your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK1f2EMfmBLk"
      },
      "source": [
        "4. What other metrics besides accuracy could we use to evaluate our model?\n",
        "    > (write your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guUoNvWXmLcc"
      },
      "source": [
        "5. How could we prevent overfitting if we noticed the test loss increasing?\n",
        "    > (write your answer here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FxVn62tpH_4"
      },
      "source": [
        "---\n",
        "\n",
        "## **Submission Instructions**\n",
        "\n",
        "- Upload your completed Notebook to your **GitHub repository**.  \n",
        "- Ensure the filename follows this format:  \n",
        "  **`CSC173_Activity02_Lastname_Firstname.ipynb`**\n",
        "- Make sure all code cells have been executed and outputs are visible.   \n",
        "- Submit the **GitHub repository link** containing your notebook in the MOLE Assignment page.  \n",
        "- **Deadline:** *November 3, 2025, 11:59 PM*\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
